%!TEX root = /Users/mortenq/Documents/ITU/Master/Realms/svn/itu_realms_project/trunk/realms_report/dk.itu.realms.main.tex
\section{Related Work} % (fold)
\label{sec:related_work}
Realms is a system supporting the creation of location-enhanced spaces through configuration. This focus requires to investigate two different areas of work; location-based applications in general, and existing systems that abstracts the creation of location based apps.

\subsection{Location-Based Applications} % (fold)
\label{sub:agumented_spaces}
Location-based applications are a special subset of context-aware applications where the main contextual information is the location of the user. Programmers of location-based apps can allow specific application behavior based on the sensed location. The behavior can be anything from sorting search results to presenting nearby restaurants, but in general, according to Schilit et. al., context aware behavior can be formalized to fall in to 4 categories: proximate selection and contextual information, automatic contextual reconfiguration, contextual commands, and context-triggered actions \cite{512740}. With the Realms system we will enable users to creation location-based behaviors, and so, we describe some interesting previous works on location-based systems.
\\\\
Location based applications have become widely popular, and both the research literature and the smartphone marketplaces host a number of different systems. These systems share different purposes, support different domains, and use location information in different ways, but they all share the common fact that they rely on location information. In this section we describe location based apps from the research literature. In our design section we will explore location applications from the smartphone market places as well.
\\\\
Location-based application come in many forms and genres. One interesting category of apps is location-based games. These games use location-information to augment a physical place with digital information - much like the vision for Realms. 
Benford et. al. describe Savannah, a mobile location-based game for exploring a virtual savannah as a pride of lions \cite{Benford_Rowland_Hull_Reid_Morrison_Facer_Clayton_2004}. The purpose of the application is to engage young people in learning - in this case about lions - through the use of mobile and game technologies. The game uses a mobile device for interaction, a GPS receiver for gathering location information and is played on a field that simulates the savannah. Throughout the game, player take on the roles as lions in a pride and are given missions - e.g. to find prey, or to explore other territories. The savannah is divided in to territories, and players location is being tracked to decide which territory they are present in. Each of these territories represent different regions of the savannah that provide different resources - e.g. grass with food or rocks with shelter. Players interact with the game by moving around and using the mobile device to use their \'senses\'. Savannah is an interesting system as its usage of location information is very similar to how we want to use it in our system.
\\\\
Pirates is another game for mobile phones that - like Savannah - uses the location of players to provide different possibilities in the game \cite{Falk:2001:PPI:634067.634140}. Instead of using absolute location and using it to determine a location in the game, however, in Pirates! proximity between players is used. In Pirates!, the setting is an archipelago, and, like in Savannah, players are given different missions to accomplish. The game field is fitted with radio frequency proximity sensor and so are the mobile devices that players use to play the game. This allows for the sensing of what is referred to as \emph{player to place proximity} and \emph{player to player proximity} respectively. These different proximities are then used to provide different possibilities for the players in the game.
\\\\
Finally, Ardito et. al. present a mobile location-enhanced system that supports history learning for young students \cite{4351331}. The system supports the exploration of archeological sites by providing extra information through a mobile devices. Moving around the archeological site, users are given small missions to accomplish. The users can then identify the place described by the mission and either digit a place code or scan the place's visual tag to tell the system that the place has been identified. Having completed the last mission, the users are presented with a 3D representation of places they have explored. 


% subsection agumented_spaces (end)

\subsection{End user programming} % (fold)
\label{sub:end_user_programming}
The creation of location-enhanced applications have become easier with the introduction of location-sensing mobile devices and programming API's that support obtaining location data. Now, the location sensors and the access to their information is directly embedded in to the environment in which location applications will run. While creating location based apps still requires programming experience, some methods have been proposed to abstract the creation of location based apps to move it from a programming to an end-user programming context. 
\\\\
Topiary is a tool for prototyping location-enhanced applications \cite{Li:2004:TTP:1029632.1029671}. It is meant for designers who want to prototype and test new location-enhanced applications. The Topiary tool is split in to three workspaces; Active Map, Storyboard, and Test. The Active Map is used to model the entities in the system. The user can upload a map and draw areas of interest while adding people and things of interest. Using these places, persons and things, users can model contextual scenarios. In the Storyboard workspace, the scenarios sketched can then be used to create conditions and links. Finally, the prototype can be run on a mobile device using the Test workspace. While Topiary can be used to create location-based prototypes it only support obtaining through PlaceLab (wifi positioning) - more fine-grained location information will have to be provided through a wizard updating the locations of the tracked users. 
\\\\
Dey et. al. present a CAPpella, a tool enabling end-users to create context-aware behavior \cite{Dey:2004:CPD:985692.985697}. Rather than enabling users to create context-aware applications, a CAPella enables users to model context-aware behavior. Users can hook up sensors with a CAPalla and record the sensor data. Afterwards this data can be annotated with information telling the program that a specific event has occurred - e.g. a user can mark a period of time where the sound level is high. Repeating this step will train the system to automatically recognize events in the sensor data - e.g. when the sound is hight. These events can then trigger user-defined actions - e.g. turning the light on. While location information is not regarded in this system, it is easy to see how location sensors could be supported.
\\\\

% subsection end_user_programming (end)
% section related_work (end)
